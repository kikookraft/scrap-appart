# SeLoger Scraper

Scraper d'annonces immobiliÃ¨res SeLoger avec authentification par cookies et contournement anti-bot DataDome.

## Architecture

```
scrap.py                          # Scraper principal (requests + lxml)
enrich_annonces.py                # Enrichissement des annonces avec dÃ©tails
extract_cookies_selenium.py       # Extracteur de cookies (Selenium + Chrome)
.cookies                          # Cookies au format JSON simple
annonces.json                     # RÃ©sultats de scraping basiques
annonces_enriched.json            # RÃ©sultats enrichis avec tous les dÃ©tails
webview/                          # Interface web de visualisation
  â”œâ”€â”€ index.html                  # Page principale
  â”œâ”€â”€ style.css                   # Styles
  â”œâ”€â”€ app.js                      # Logique JavaScript
  â”œâ”€â”€ server.py                   # Serveur web Python
  â”œâ”€â”€ README_WEBVIEW.md           # Documentation du visualiseur
  â”œâ”€â”€ annonces.json               # Copie des annonces (auto-gÃ©nÃ©rÃ©e)
  â””â”€â”€ annonces_enriched.json      # Copie des annonces enrichies (auto-gÃ©nÃ©rÃ©e)
```

## Installation

```bash
pip install -r requirements.txt
```

**DÃ©pendances:**
- `requests` (2.31.0+) - HTTP client
- `lxml` (4.9.0+) - Parser HTML/XPath
- `selenium` (4.38.0+) - Automation navigateur
- `webdriver-manager` (4.0.1+) - Gestion ChromeDriver automatique

## Extraction des cookies

```bash
python3 extract_cookies_selenium.py
```

**Processus:**
1. Lance Chrome avec options anti-dÃ©tection
2. Ouvre SeLoger.com
3. Attend que l'utilisateur navigue et se connecte manuellement
4. Appuyer sur ENTRÃ‰E dans le terminal
5. Extrait tous les cookies automatiquement
6. Sauvegarde dans `.cookies` (format simple) et `.cookies.full` (format complet)

**Cookies critiques:**
- `datadome` - Protection anti-bot (expire rapidement)
- `visitId` - Session utilisateur
- `_ga`, `_gid` - Google Analytics

**DurÃ©e de vie:** < 1 heure (recommandÃ©: extraire juste avant scraping)

## Scraping

```bash
python3 scrap.py                  # 1 page (~27 annonces)
python3 scrap.py --max-pages 5    # 5 pages (~135+ annonces)
```

**Filtres par dÃ©faut:**
- Prix: max 1500â‚¬
- Surface: min 65mÂ²
- Chambres: min 3
- Villes: Lyon (690123) + Tassin-la-Demi-Lune (690244)
- Type: Location d'appartements/maisons

**URL gÃ©nÃ©rÃ©e:**
```
https://www.seloger.com/list.htm?projects=1&types=1,2&places=[{ci:690123},{ci:690244}]&price=NaN/1500&surface=65/NaN&bedrooms=3
```

**Options CLI:**
```bash
python3 scrap.py --url "https://..."        # URL personnalisÃ©e
python3 scrap.py --output results.json      # Fichier sortie
python3 scrap.py --max-pages 10             # Nombre de pages
python3 scrap.py --max-pages 3 --output appartements_lyon.json
```

**Pagination:**
- SeLoger limite Ã  ~27 annonces par page
- ParamÃ¨tre: `&LISTING-LISTpg=2` pour page 2
- DÃ©duplication automatique par URL
- DÃ©lai 3-5s entre pages (anti-bot)
- RÃ©indexation des IDs (1, 2, 3...)

## Techniques anti-bot

**Headers rÃ©alistes:**
```python
User-Agent: Mozilla/5.0 Chrome/131.0.0.0
Accept-Encoding: gzip, deflate, br, zstd
Sec-Fetch-Dest: document
Sec-Fetch-Mode: navigate
Sec-Fetch-Site: same-origin
```

**Comportement humain:**
1. Visite page d'accueil (`/`)
2. DÃ©lai alÃ©atoire 1.5-3s
3. Navigation vers recherche avec `Referer` header
4. DÃ©lai alÃ©atoire 2-4s entre requÃªtes

**Session persistante:** Conservation des cookies via `requests.Session()`

## Enrichissement des annonces

Une fois les annonces rÃ©cupÃ©rÃ©es avec `scrap.py`, utilisez `enrich_annonces.py` pour obtenir tous les dÃ©tails:

```bash
# Enrichir les annonces du fichier annonces.json
python3 enrich_annonces.py

# Avec options personnalisÃ©es
python3 enrich_annonces.py --input annonces.json --output annonces_enriched.json

# Tester sur les 5 premiÃ¨res annonces
python3 enrich_annonces.py --limit 5
```

**Informations ajoutÃ©es:**
- ðŸ“ **GPS**: Latitude et longitude (coordonnÃ©es prÃ©cises)
- ðŸ™ï¸ **Localisation nettoyÃ©e**: Ville et quartier extraits proprement
- âš¡ **DPE**: Diagnostic de Performance Ã‰nergÃ©tique (A-G)
- ðŸŒ **GES**: Ã‰missions de Gaz Ã  Effet de Serre (A-G)
- ðŸ–¼ï¸ **Images**: URLs de toutes les photos de l'annonce
- ðŸ“ **Surface nettoyÃ©e**: Extraction numÃ©rique (float) de la surface en mÂ²
- ðŸ“… **Date de rÃ©cupÃ©ration**: Timestamp ISO 8601 de l'enrichissement
- ðŸ“… **Date de publication**: Date de mise en ligne de l'annonce

**Options CLI:**
```bash
python3 enrich_annonces.py --input annonces.json        # Fichier d'entrÃ©e
python3 enrich_annonces.py --output enriched.json       # Fichier de sortie
python3 enrich_annonces.py --cookies .cookies           # Fichier de cookies
python3 enrich_annonces.py --limit 10                   # Limiter pour tests
```

**Format de sortie (annonces_enriched.json):**
```json
[
  {
    "id": 1,
    "url": "https://www.seloger.com/annonces/locations/...",
    "title": "Appartement meublÃ©",
    "price": "500 â‚¬",
    "location": "Lyon 8Ã¨me (69008)",
    "surface": "105 mÂ²",
    "bedrooms": "3 chambres",
    "gps_latitude": 45.7640,
    "gps_longitude": 4.8357,
    "ville": "Lyon 8Ã¨me",
    "quartier": "Monplaisir",
    "dpe": "C",
    "ges": "B",
    "images": [
      "https://v.seloger.com/s/crop/590x330/...",
      "https://v.seloger.com/s/crop/590x330/..."
    ],
    "surface_clean": 105.0,
    "date_recuperation": "2026-02-17T14:30:00",
    "date_publication": "2026-02-10"
  }
]
```

**Workflow complet:**
```bash
# 1. Extraire les cookies (valides < 1h)
python3 extract_cookies_selenium.py

# 2. Scraper les annonces (donnÃ©es basiques)
python3 scrap.py --max-pages 5 --output annonces.json

# 3. Enrichir avec dÃ©tails complets
python3 enrich_annonces.py --input annonces.json --output annonces_enriched.json

# 4. Copier les annonces dans le dossier webview
cp annonces.json annonces_enriched.json webview/

# 5. Lancer le visualiseur web
cd webview && python3 server.py
# Puis ouvrir http://localhost:8000 dans le navigateur
```

**Performance:**
- DÃ©lai: 2-4s entre chaque annonce (anti-bot)
- DurÃ©e: ~3min pour 50 annonces
- Statistiques affichÃ©es en fin de traitement

## XPath Selectors (Mis Ã  jour 2026)

SeLoger change rÃ©guliÃ¨rement sa structure HTML. SÃ©lecteurs actuels:

```python
# Conteneurs d'annonces
"//div[@data-testid='sl.explore.card-container']"

# URL de l'annonce
".//a[@data-testid='sl.explore.coveringLink']/@href"

# Prix
".//div[@data-testid='sl.explore-card-price']//text()"

# Textes: titre, localisation, surface, chambres
".//text()"  # Filtrage par patterns (mÂ², chambres, codes postaux)
```

**Si 0 rÃ©sultats:**
1. VÃ©rifier cookies valides et rÃ©cents
2. Inspecter HTML sauvegardÃ©
3. Identifier nouveaux `data-testid` dans le DOM
4. Mettre Ã  jour XPath dans `_parse_listings()`

## Format de sortie (annonces.json)

```json
[
  {
    "id": 1,
    "url": "https://www.seloger.com/annonces/locations/...",
    "title": "Appartement meublÃ©",
    "price": "500 â‚¬",
    "location": "Lyon 8Ã¨me (69008)",
    "surface": "105 mÂ²",
    "bedrooms": "3 chambres"
  }
]
```

## Troubleshooting

**403 Forbidden:**
- Cookies expirÃ©s â†’ RÃ©-extraire avec Selenium
- Cookie `datadome` manquant â†’ VÃ©rifier `.cookies`
- IP blacklistÃ©e temporairement â†’ Attendre 5-10 min

**0 annonces trouvÃ©es (status 200):**
- HTML structure changÃ©e â†’ Analyser XPath selectors
- Script debug rapide:
```python
from lxml import html
doc = html.fromstring(open('response.html', 'rb').read())
len(doc.xpath("//div[@data-testid='sl.explore.card-container']"))
```

**Selenium crash:**
- Chrome/Chromium manquant â†’ `apt install chromium-browser`
- Permissions â†’ `chmod +x chromedriver`
- Headless fail â†’ Retirer `--headless` des options Chrome

## Structure du code

### scrap.py - SeLogerScraper class

```python
__init__(cookies_file)          # Charge cookies, configure session
_load_cookies()                 # Parse JSON/text cookies â†’ session
build_search_url(filters)       # Construit URL avec paramÃ¨tres
search(filters, url, max_pages) # Visite homepage â†’ scrape N pages
_parse_listings(html_content)   # XPath extraction â†’ liste dicts
save_to_json(results, filename) # Dump JSON avec encoding UTF-8
```

**Pagination interne:**
- Boucle sur `max_pages` (dÃ©faut: 1)
- Ajoute `&LISTING-LISTpg=N` Ã  l'URL
- Visite homepage (page 1 uniquement)
- Accumule rÃ©sultats dans `all_results`
- DÃ©duplique par URL avec `set()`
- RÃ©indexe IDs de 1 Ã  N
- DÃ©lai 3-5s entre pages

### enrich_annonces.py - AnnonceEnricher class

```python
__init__(cookies_file)                  # Configure session avec cookies
extract_details_from_page(url)          # Scrape page annonce complÃ¨te
clean_surface(surface_str)              # Extrait float depuis "105 mÂ²"
clean_location(location_str)            # Parse ville/quartier
enrich_annonces(annonces)               # Enrichit liste complÃ¨te
save_to_json(results, filename)         # Sauvegarde JSON enrichi
```

**Extraction des dÃ©tails:**
- JSON-LD structured data (GPS, adresse)
- XPath sur Ã©lÃ©ments `data-*` (DPE, GES)
- Regex pour dates et surfaces
- Galerie d'images (dÃ©dupliquÃ©es)
- DÃ©lai 2-4s entre annonces

### extract_cookies_selenium.py - CookieExtractor class

```python
__init__()                      # Configure Chrome avec options anti-bot
navigate_to_seloger()           # Ouvre SeLoger dans Chrome
wait_for_user_interaction()     # Pause pour login manuel
extract_cookies()               # RÃ©cupÃ¨re tous les cookies du driver
save_cookies_simple_format()    # Sauvegarde JSON simple
save_cookies_full_format()      # Sauvegarde JSON complet avec metadata
verify_cookies()                # VÃ©rifie prÃ©sence cookies critiques
```

## ParamÃ¨tres modifiables

**Filtres de recherche (scrap.py ligne ~120):**
```python
default_filters = {
    'projects': '1',              # 1=Location, 2=Vente
    'types': '1,2',               # 1=Appart, 2=Maison, 4=Parking
    'places': '[{ci:690123},{ci:690244}]',  # Codes INSEE
    'price': 'NaN/1500',         # Min/Max
    'surface': '65/NaN',         # Min/Max mÂ²
    'bedrooms': '3',             # Min chambres
}
```

**DÃ©lais anti-bot (scrap.py ligne ~58):**
```python
self._min_delay = 2.0  # secondes
self._max_delay = 4.0
```

**Codes INSEE villes (Ã  ajouter dans `places`):**
- Lyon: 690123
- Tassin-la-Demi-Lune: 690244
- Villeurbanne: 690266
- VÃ©nissieux: 690259

Format: `[{ci:690123},{ci:690244},{ci:690266}]`

## Notes techniques

**Protection DataDome:**
- Fingerprinting navigateur (Canvas, WebGL, fonts)
- Analyse comportementale (mouvements souris, timing)
- Challenge invisible (JavaScript, cookies)
- Contournement: cookies extraits d'un vrai navigateur

**Selenium options critiques:**
```python
--disable-blink-features=AutomationControlled
--disable-dev-shm-usage
--no-sandbox
user-agent=Mozilla/5.0...
```

**Limites:**
- Cookies < 1h de validitÃ©
- Rate limiting: ~1 requÃªte/2-4s recommandÃ©
- Pagination: ~27 annonces/page (testÃ©e jusqu'Ã  10 pages)
- Photos non tÃ©lÃ©chargÃ©es (URLs disponibles dans HTML)
- Limite SeLoger: ~5-10 pages max par recherche

## Visualisation Web

Un visualiseur web moderne est disponible dans le dossier `webview/`. Il permet de consulter les annonces rÃ©cupÃ©rÃ©es avec une interface Ã©lÃ©gante et intuitive.

**FonctionnalitÃ©s:**
- ðŸ” Recherche en temps rÃ©el (titre, localisation, prix)
- ðŸ”„ Tri par prix ou surface (croissant/dÃ©croissant)
- ðŸ–¼ï¸ Galerie d'images pour chaque annonce
- ðŸ“± Design responsive (mobile & desktop)
- ðŸ—ºï¸ Affichage GPS, DPE, GES si disponibles
- ðŸ·ï¸ Tags visuels pour les caractÃ©ristiques

**Lancement rapide:**
```bash
cd webview
python3 server.py
# Ouvrir http://localhost:8000 dans votre navigateur
```

**Mise Ã  jour des donnÃ©es:**
```bash
# AprÃ¨s chaque scraping, copier les nouvelles annonces
cp annonces.json annonces_enriched.json webview/
```

Pour plus de dÃ©tails, consultez `webview/README_WEBVIEW.md`.
